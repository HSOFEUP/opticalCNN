Deep neural networks have found success in a wide variety of applications, ranging from computer vision to natural language processing to game playing \cite{lecun2015deep}. Since the explosion of interest following the achievements of convolutional neural networks on ImageNet classification, deep learning has transformed algorithms in both academic and commercial environments. While accuracy has improved to a remarkable level, the number of parameters and connections has grown dramatically, and the power requirements to build and use these networks have increased correspondingly. 

While the training phase of learning parameter weights is often considered the slow stage, large models also demand significant energy during inference due to millions of repeated memory references. For example, AlphaGo has a power consumption of approximately 300 W. To this end, there is a large effort to develop new software methods and specialty hardware for improved efficiency. Algorithms for improved efficiency include pruning, quantization, low rank, parallelization, mixed precision, and model distillation. Compressed models have demonstrated preserved accuracy with much fewer parameters \cite{han2015deep,iandola2016squeezenet}. On the hardware front, there are now specialized processing units for deep learning, such as TrueNorth, Movidius's USB-based neural compute stick (NCS), and Google's tensor processing unit (TPU). Despite all these efforts, it remains difficult for embedded systems such as mobile vision, autonomous vehicles/robots, and wireless smart sensors to deploy CNNs due to stringent constraints on power and bandwidth. 

Optical computing has been tantalizing for its high bandwidth and inherently parallel processing. If we can come up with scalable optical configurations that together act as a framework for an optical CNN, this would be of interest to computer vision, robotics, machine learning, and optics communities. Optical neural networks (ONNs) could also potentially exploit wave optics for complex-valued neural networks and new types of non-linearities that are currently unavailable to digital computation. Linear transformations can be performed with lens systems or interferometer meshes \cite{shen2017deep}. Optical nonlinearities include saturable absorption and bistability. Convolutions are commonly performed with PSF engineering.
Fourier optics
 We use these to propose a model for cascaded parallel convolutions with sandwiched nonlinearity layers.

In this paper, we follow the vein of computational photography to create we zero-power, all-optical convolutional neural network for image classification. 

reduce the workload of the electronic processor


We choose a simple classification task, e.g. MNIST, GoogleQuickdraw, or CIFAR-10, and build a prototype that performs classification on projected images. We precompute the weights by supervised learning on a computer, then fabricate the optical elements accordingly. We compare performance with the same inference performed on the computer, with and without the simulated physical constraints of an optical setup. Here we demonstrate proof-of-concept with bulk optics and free-space propagation, but we recommend photonic integrated circuits for scalability. Photonic circuits with up to 4,096 optical devices have been demonstrated \cite{sun2013large}, and there have also been new three-dimensional photonic integrations that could enable larger networks \cite{rechtsman2013photonic}. Combination of these next-generation large-scale photonic circuits with compressed deep learning models could provide a potential route for high performance ONNs.

To summarize, we make the following contributions:
\begin{itemize}
\item We propose an optical toolbox of building blocks for convolutional neural networks. 
\item Simulation framework
\item We build a hybrid optoelectronic two-layer network with an optical convolutional layer and electronic fully connected layer for CIFAR-10 classification. 
\item We evaluate against the computer implementation of the same network and show that we achieve similar accuracy.
\end{itemize}

\textit{Overview of limitations.} 
While the proposed ONN architecture offers zero-power inference on classification tasks, the physical image formation adds several constraints to the CNN architecture, including nonnegative weights, no bias, limited set of nonlinearities, etc. These constraints ultimately limit the performance of our system, and we discuss/analyze/evaluate them in detail in this paper.

We are limited to non-negative values since we are working with light intensities. This may be avoided with coherent processing. We also hope to proceed without normalization. We focus here on inference and do training on the computer. In our current implementation without active elements, we lose flexibility to update the network. However, in fixed applications, this is not a problem. Photonic circuits remain expensive to fabricate as they are not used in common consumer applications.
